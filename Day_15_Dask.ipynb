{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "923fd110-4f13-4b03-bdf1-73933f2ee55e",
   "metadata": {},
   "source": [
    "####  What is Dask?\n",
    "##### Dask is a flexible, parallel computing library in Python for big data and performance-optimized workflows. It scales your computations across cores, threads, or even clusters, using familiar APIs like Pandas, NumPy, and scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011c7de2-e4bc-49bb-ae2c-7073beda0fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚙️ Core Functionalities of Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64da6ced-ca9e-4c86-8884-e713238881e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area                   Functionality                  API\n",
      "---------------------  -----------------------------  ---------------------------\n",
      "Big Dataframes         Parallelized Pandas            dask.dataframe\n",
      "Big Arrays             Parallelized NumPy             dask.array\n",
      "Parallel Functions     Lazy task scheduling           dask.delayed, dask.compute\n",
      "Machine Learning       Parallel ML with scikit-learn  dask-ml\n",
      "Distributed Computing  Scale to clusters              dask.distributed\n",
      "Streaming              Stream processing              dask.streams (experimental)\n",
      "Graphs                 Task-based DAG execution       dask.graph\n"
     ]
    }
   ],
   "source": [
    "dask_info = [\n",
    "    {\"Area\": \"Big Dataframes\", \"Functionality\": \"Parallelized Pandas\", \"API\": \"dask.dataframe\"},\n",
    "    {\"Area\": \"Big Arrays\", \"Functionality\": \"Parallelized NumPy\", \"API\": \"dask.array\"},\n",
    "    {\"Area\": \"Parallel Functions\", \"Functionality\": \"Lazy task scheduling\", \"API\": \"dask.delayed, dask.compute\"},\n",
    "    {\"Area\": \"Machine Learning\", \"Functionality\": \"Parallel ML with scikit-learn\", \"API\": \"dask-ml\"},\n",
    "    {\"Area\": \"Distributed Computing\", \"Functionality\": \"Scale to clusters\", \"API\": \"dask.distributed\"},\n",
    "    {\"Area\": \"Streaming\", \"Functionality\": \"Stream processing\", \"API\": \"dask.streams (experimental)\"},\n",
    "    {\"Area\": \"Graphs\", \"Functionality\": \"Task-based DAG execution\", \"API\": \"dask.graph\"},\n",
    "]\n",
    "\n",
    "# Optional: print it as a table using tabulate\n",
    "from tabulate import tabulate\n",
    "print(tabulate(dask_info, headers=\"keys\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43d32cc8-8026-4382-856a-a6e7056beb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Area                  Functionality  \\\n",
      "0         Big Dataframes            Parallelized Pandas   \n",
      "1             Big Arrays             Parallelized NumPy   \n",
      "2     Parallel Functions           Lazy task scheduling   \n",
      "3       Machine Learning  Parallel ML with scikit-learn   \n",
      "4  Distributed Computing              Scale to clusters   \n",
      "5              Streaming              Stream processing   \n",
      "6                 Graphs       Task-based DAG execution   \n",
      "\n",
      "                           API  \n",
      "0               dask.dataframe  \n",
      "1                   dask.array  \n",
      "2   dask.delayed, dask.compute  \n",
      "3                      dask-ml  \n",
      "4             dask.distributed  \n",
      "5  dask.streams (experimental)  \n",
      "6                   dask.graph  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dask_data = {\n",
    "    \"Area\": [\n",
    "        \"Big Dataframes\", \"Big Arrays\", \"Parallel Functions\", \"Machine Learning\",\n",
    "        \"Distributed Computing\", \"Streaming\", \"Graphs\"\n",
    "    ],\n",
    "    \"Functionality\": [\n",
    "        \"Parallelized Pandas\", \"Parallelized NumPy\", \"Lazy task scheduling\",\n",
    "        \"Parallel ML with scikit-learn\", \"Scale to clusters\",\n",
    "        \"Stream processing\", \"Task-based DAG execution\"\n",
    "    ],\n",
    "    \"API\": [\n",
    "        \"dask.dataframe\", \"dask.array\", \"dask.delayed, dask.compute\",\n",
    "        \"dask-ml\", \"dask.distributed\", \"dask.streams (experimental)\", \"dask.graph\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dask_data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0be8e39-b4e8-4dac-98fd-166f2c478106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask[complete] in c:\\users\\rahul\\anaconda3\\lib\\site-packages (2024.8.2)\n",
      "Requirement already satisfied: click>=8.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dask[complete]) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dask[complete]) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dask[complete]) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dask[complete]) (24.1)\n",
      "Requirement already satisfied: partd>=1.4.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dask[complete]) (1.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dask[complete]) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dask[complete]) (0.12.0)\n",
      "Requirement already satisfied: pyarrow>=14.0.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dask[complete]) (16.1.0)\n",
      "Requirement already satisfied: lz4>=4.3.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dask[complete]) (4.3.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from click>=8.1->dask[complete]) (0.4.6)\n",
      "Requirement already satisfied: locket in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from partd>=1.4.0->dask[complete]) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pyarrow>=14.0.1->dask[complete]) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dask[complete]) (2.2.2)\n",
      "Requirement already satisfied: dask-expr<1.2,>=1.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dask[complete]) (1.1.13)\n",
      "Requirement already satisfied: bokeh>=2.4.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dask[complete]) (3.6.0)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dask[complete]) (3.1.4)\n",
      "Requirement already satisfied: distributed==2024.8.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dask[complete]) (2024.8.2)\n",
      "Requirement already satisfied: msgpack>=1.0.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from distributed==2024.8.2->dask[complete]) (1.0.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from distributed==2024.8.2->dask[complete]) (5.9.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from distributed==2024.8.2->dask[complete]) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from distributed==2024.8.2->dask[complete]) (1.7.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from distributed==2024.8.2->dask[complete]) (6.4.1)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from distributed==2024.8.2->dask[complete]) (2.2.3)\n",
      "Requirement already satisfied: zict>=3.0.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from distributed==2024.8.2->dask[complete]) (3.0.0)\n",
      "Requirement already satisfied: contourpy>=1.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from bokeh>=2.4.2->dask[complete]) (1.2.0)\n",
      "Requirement already satisfied: pillow>=7.1.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from bokeh>=2.4.2->dask[complete]) (10.4.0)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from bokeh>=2.4.2->dask[complete]) (2022.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from jinja2>=2.10.3->dask[complete]) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pandas>=2.0->dask[complete]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pandas>=2.0->dask[complete]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pandas>=2.0->dask[complete]) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[complete]) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install dask[complete]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59da636-243d-4de6-af4e-6ed65de15e58",
   "metadata": {},
   "source": [
    "#### ✅ Common Use Cases\n",
    "#### 1 Handle CSVs that don’t fit in memory\n",
    "\n",
    "#### 2 Large matrix computations (e.g., climate, imaging, ML)\n",
    "\n",
    "#### 3 Parallel data processing (ETL)\n",
    "\n",
    "#### 4 Scalable ML training using Dask-ML\n",
    "\n",
    "#### 5 Processing millions of rows like Pandas but faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3912e666-f4a3-428c-9430-d7e9f506fd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+--------------------------------------+\n",
      "| Feature     | Pandas          | Dask                                 |\n",
      "+=============+=================+======================================+\n",
      "| Memory      | Single machine  | Out-of-core (disk, memory-efficient) |\n",
      "+-------------+-----------------+--------------------------------------+\n",
      "| Performance | Single-threaded | Multi-threaded/cluster               |\n",
      "+-------------+-----------------+--------------------------------------+\n",
      "| Syntax      | Easy            | Same syntax as Pandas                |\n",
      "+-------------+-----------------+--------------------------------------+\n",
      "| Scale       | GBs             | 100s of GBs to TBs                   |\n",
      "+-------------+-----------------+--------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "data = [\n",
    "    [\"Memory\", \"Single machine\", \"Out-of-core (disk, memory-efficient)\"],\n",
    "    [\"Performance\", \"Single-threaded\", \"Multi-threaded/cluster\"],\n",
    "    [\"Syntax\", \"Easy\", \"Same syntax as Pandas\"],\n",
    "    [\"Scale\", \"GBs\", \"100s of GBs to TBs\"]\n",
    "]\n",
    "\n",
    "headers = [\"Feature\", \"Pandas\", \"Dask\"]\n",
    "\n",
    "print(tabulate(data, headers=headers, tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50d6fee-2994-4953-aa3f-15cd57f7dcfd",
   "metadata": {},
   "source": [
    "### 1. Dask DataFrame (for Big CSVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72ec02af-94ec-4f31-8df1-c5e5cd5b5c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "Clothing        57.311667\n",
      "Electronics    794.207778\n",
      "Name: sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Load large CSV\n",
    "df = dd.read_csv('big_sales_data.csv')\n",
    "\n",
    "# Operations (lazy, parallel)\n",
    "result = df.groupby('category')['sales'].mean().compute()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f98d858-23ee-41b5-9aaf-befbb42105c4",
   "metadata": {},
   "source": [
    "### 2. Dask Array (like NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba76c9c4-3e16-44f6-90f3-270efbca1798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.49998041051119124\n"
     ]
    }
   ],
   "source": [
    "import dask.array as da\n",
    "\n",
    "# Create large random array\n",
    "x = da.random.random((10000, 10000), chunks=(1000, 1000))\n",
    "mean = x.mean().compute()\n",
    "print(\"Mean:\", mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c90274-28c0-4050-a76a-aa23f7dd1f72",
   "metadata": {},
   "source": [
    "### 🏗️ 3. Dask Delayed (Custom Parallel Tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4957f91-dc52-4a68-afa3-1156100effdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 35\n"
     ]
    }
   ],
   "source": [
    "from dask import delayed\n",
    "\n",
    "@delayed\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "@delayed\n",
    "def multiply(x, y):\n",
    "    return x * y\n",
    "\n",
    "# Create task graph\n",
    "final = add(multiply(10, 2), multiply(5, 3))\n",
    "print(\"Result:\", final.compute())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395dc768-c97c-45cc-b7aa-11fd6df88da0",
   "metadata": {},
   "source": [
    "### ⚡ 4. Dask with Distributed Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b05fec62-cefe-4e90-b096-9052d9b96189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:52013' processes=4 threads=4, memory=11.89 GiB>\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()  # Local cluster\n",
    "print(client)\n",
    "\n",
    "# Now you can run dask jobs in parallel threads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc1342-5f0b-4cf7-8c76-2097f52a6cd8",
   "metadata": {},
   "source": [
    "### ✅ Pros of Dask\n",
    "#### ✅ Parallel & Efficient: Multithreading and multiprocessing out-of-the-box\n",
    "#### ✅ Out-of-Core: Works with datasets larger than RAM\n",
    "#### ✅ Familiar APIs: Very similar to Pandas, NumPy, scikit-learn\n",
    "#### ✅ Scalable: Can run on a laptop or 100-node cluster\n",
    "#### ✅ Lazy Evaluation: Builds computation graphs for optimization\n",
    "#### ✅ Dashboard: Built-in performance dashboard (when using distributed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cbfe99-ddf6-4579-8a81-0bd23073270a",
   "metadata": {},
   "source": [
    "### ❌ Cons of Dask\n",
    "#### ❌ Slower on small data (due to overhead of parallelism)\n",
    "#### ❌ Debugging can be tricky in lazy evaluations\n",
    "#### ❌ Not all Pandas operations are supported (e.g., .pivot_table())\n",
    "#### ❌ Learning Curve for cluster deployment\n",
    "#### ❌ Latency in small task scheduling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
